面试提纲

我熟悉Java语言和python语言，做过springboot相关项目，熟悉mysql数据库和linux环境，了解前端基础知识。有较好的规范编码习惯，坚持写技术博客，在博客园等平台发布超500篇随笔，阅读量破十万。以510分的成绩通过英语六级，在校曾担任学院主持人，曾主持大小多个活动比赛等。

# 1、1.8新特性

接口、foreach、hashmap和Arraylist 初始化、元空间

# 2、集合

初始容量、扩容方式和大小、加载因子

# 3、线程池

执行逻辑

ThreadPoolExecutor7个参数 **corePoolSize、maximumPoolSize、keepAliveTime、unit、workQueue、threadFactory、handler** 

# 4、JVM内存模型

**线程私有区域:程序计数器、Java虚拟机栈、本地方法栈
线程共享区域:Java堆、方法区**

# 5、B树、B+树、红黑树

异同点

B：阶和关键字

B+：只在叶子节点保存数据且链表指针相连

红黑：黑相同，红不相邻，非严格二查搜索树。红黑相间的子树只可能比全黑的子树高一倍

# 6、事务的特点、mysql事务隔离级别

事务是什么、特点、隔离级别

# 7、TCP三次握手

序列号和ack的执行过程、为什么是三次

# 8、InnoDB与MyISAM区别

事务、主键、主键索引基于聚簇索引、行级锁、非聚簇索引的回表。

# 9、== 和 equals 

区别、重写

# 10、bean创建过程和生命周期

BeanDefinition、BeanDefinitionRegistry、DefaultListableBeanFactory、getBean、doCreateBean、populateBean、initializeBean

1.实例化 Instantiation
2.属性赋值 Populate
3.初始化 Initialization
4.销毁 Destruction

# 11、Spring 用到的设计模式

动态代理：代理类实现InvocationHandler。我们可以运用AOP的思想，把和主干业务无关的功能代码给抽取出来，然后在这些功能运行时将其动态的横向插入进去，减少耦合度和代码冗余。

适配器模式：DispatcherServlet、HandlerAdapter

简单工厂模式：BeanFactory创建对象

单例模式：数据库连接池、线程池、缓存、日志等全局只有一个实例，bean的默认作用域就是singleton。

# 12、hadoop

分布式文件系统 HDFS(Hadoop Distributed File System)

分布式计算系统 MapReduce

分布式资源管理系统 YARN

# 13、docker

镜像：类

容器：对象

仓库：保存镜像

# 14、hash索引

Memory、数据值存在数组，用一个hash函数把key转换成一个确定的内存位置，然后把value放在数组的该位置。

为什么hashmap扩容都是2的次幂

HashMap的容量为什么是2的n次幂，和这个(n - 1) & hash的计算方法有着千丝万缕的关系，符号&是按位与的计算，这是位运算，计算机能直接运算，特别高效，按位与&的计算方法是，只有当对应位置的数据都为1时，运算结果也为1，当HashMap的容量是2的n次幂时，(n-1)的2进制也就是1111111***111这样形式的，这样与添加元素的hash值进行位运算时，能够充分的散列，使得添加的元素均匀分布在HashMap的每个位置上，减少hash碰撞。
# 15、I/0流

字符字节、输入输出

FileReader、FileWriter、FileInputStream、FileOutputStream、InputStreamReader、OutputStreamWriter

# 16、线程

Thread、Runnable、Callable【返回值和异常 call( )】

生命周期：新建、就绪、运行、阻塞、死亡

# 17、线程同步

线程状态

![image-20221001104614904](https://raw.githubusercontent.com/SAH01/wordpress-img/master/imgs/image-20221001104614904.png)

public static synchronized void show()  同步代码块和同步方法

Lock锁【lock.lock( ); lock.unlock( );】

# 18、线程通信

- 共享内存：线程之间共享程序的公共状态，线程之间通过读-写内存中的公共状态来隐式通信。**volatile** 本地内存【副本变量】刷新到主内存【共享变量】。

- 消息传递：线程之间没有公共的状态，线程之间必须通过明确的发送信息来显示的进行通信。

    wait/notify
    join

- 管道 PipedOutputStream

# 19、JDK和JMM

**jdk（javac）>jre（java）>jvm**

Java内存模型规定**所有的变量都存储在主内存**中，包括实例变量，静态变量，但是不包括局部变量和方法参数。每个线程都有自己的工作内存，**线程的工作内存保存了该线程用到的变量和主内存的副本拷贝，线程对变量的操作都在工作内存中进行**。**线程不能直接读写主内存中的变量**。

不同的线程之间也无法访问对方工作内存中的变量。线程之间变量值的传递均需要通过主内存来完成。

![img](https://raw.githubusercontent.com/SAH01/wordpress-img/master/imgs/v2-f36f366c07a6188ea3fdefc794ba021a_r.jpg)

# 20、垃圾回收

如何判断是否是垃圾：引用计数、可达性分析

标记-清除

标记-复制

标记-整理

# 21、面向对象

封装：隐藏、私有的属性，公有的方法，高内聚低耦合

继承：子类继承父类的特征和行为，也可以改变

多态：根据模板实现细节，重载和重写。

# 22、SpringBoot

starter 提供了一个自动化配置类，一般命名为 `XXXAutoConfiguration` ，在这个配置类中通过条件注解来决定一个配置是否生效。

SpringBoot通过一个自动配置和启动的项来解决配置大量的参数的问题。

==Spring Boot 能根据当前类路径下的类、jar 包来自动配置 bean，如添加一个 spring-boot-starter-web 启动器就能拥有 web 的功能，无需其他配置。==避免大量的Maven导入和各种版本冲突。

spring-boot-starter-parent 中有很多父依赖dependencies

**@SpringBootApplication** 标明主配置类

**@ComponentScan**自动扫描并加载当前主启动类同级的所有包作为bean，将这个bean定义加载到IOC容器中

我们所需的配置项都在**springboot-autoconfigure**的jar包中

> 自动配置的真正实现是从classpath中搜索所有的META-INF/spring factories配置文件，并将其中对应的autoconfigure包下的配置项通过反射实例化为对应的@Configuration的javaConfig形式的IOC容器配置类，然后将这些汇总成为一个实例并加载到IOC容器中 

# 23、Mybatis

一级缓存【SqlSession】和二级缓存【namespace】

1：创建 SqlSessionFactory。

2：通过 SqlSessionFactory 创建 SqlSession。

3：通过 SqlSession 执行数据库操作。

4：调用 session.commit() 提交事务。

5：调用 session.close() 关闭会话。

# 24、SSO

单点登录的本质就是在多个应用系统中共享登录状态。

# 25、Redis

expire key seconds

append key value

Redis（Remote Dictionary Server )，即远程字典服务，Key-Value数据库

RDB快照和AOF重写

主从复制 主写从读 主节点复制到从节点 从节点首先发起连接并全量复制主节点的数据

发布订阅  	publish channel message 	subscribe channel [channel ...]

哨兵模式 独立进程 发送命令等待服务器响应

- 当哨兵监测到master宕机，会自动将slave切换成master，然后通过**发布订阅模式**通知其他的从服务器，修改配置文件，让它们切换主机。

缓存穿透、击穿、雪崩

# 26、Flume

生成、收集数据

管道流、日志采集、聚合、传输

Agent 是一个 JVM 进程，它以事件的形式将数据从源头送至目的。Agent 主要有 3 个部分组成，Source、Channel、Sink。

Channel【线程安全、File Channel 、File Channel】

数据传输基本单元是Event

# 27、Kafka

消费数据：/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

分离订单和库存系统【例子】

producer 将消息推送到 broker，consumer 从broker 拉取消息。

服务器、队列、分区

Kafka 采用拉取（pull）模型，**由消费者自己记录消费状态，每个消费者互相独立地顺序读取每个分区的消息**。

消费者每次消费数据时，消费者都会记录消费的物理偏移量（offset），等下次消费时，会接着上次位置继续消费。

# 28、限流降级

限流：秒杀

降级：保护核心服务

# 29、Spark

实时内存计算，中间结果不用存入磁盘

多线程计算、共享内存资源

# 30、hdfs

Master/Slave的架构

HDFS Client、NameNode【文件系统管理、名称、存储的节点位置】、DataNode【存储文件数据block】和Secondary NameNode。

# 31、mongodb

基于分布式文件存储的开源数据库系统

MongoDB中的文档本质是**一种类似JSON的BSON格式的数据**。

BSON是一种类似JSON的**二进制格式数据**，它可理解为在JSON基础上添加了一些新的数据类型。



文档就是键值对的一个有序集合

MongoDB 文档数据库的存储结构分为四个层次，从大到小依次是：数据库（database）、集合（collection）、文档（document）、键值对。

| table  | collection | 数据库表/集合   |
| ------ | ---------- | --------------- |
| row    | document   | 数据记录行/文档 |
| column | field      | 数据字段/域     |
| index  | index      | 索引            |

# 32、hive和hbase

Hive：Hive是基于Hadoop的一个**数据仓库工具**，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能。

HBase：HBase是Hadoop的**数据库**，一个分布式、可扩展、大数据的存储。

**Hbase主要解决实时数据查询问题，Hive主要解决数据处理和计算问题**

----

Hive的元数据一般存储在[关系型数据库](https://www.yisu.com/mysql/)中，如[MySql](https://www.yisu.com/mysql/);【元数据 ： 描述数据的数据，例如数据表的大小是100KB,数据表是数据，表大小是数据的数据】

- 存储位置：Hive在Hadoop上；Mysql将数据存储在设备或本地系统中；
- 数据更新：Hive不支持数据的改写和添加，是在加载的时候就已经确定好了；数据库可以CRUD；
- 索引：Hive无索引，每次扫描所有数据，底层是MR，并行计算，适用于大数据量；MySQL有索引，适合在线查询数据；
- 执行：Hive底层是MarReduce；MySQL底层是执行引擎；

----

# 33、
